---
title: "CatBoost ã® feature importance"
emoji: "ğŸˆ" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["æ©Ÿæ¢°å­¦ç¿’"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: true # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

# æ¦‚è¦
CatBoost ãŒè¨ˆç®—ã—ã¦ãã‚Œã‚‹ feature importance ã®å®šç¾©ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¦ã‚‚ã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã®ã§èª¿ã¹ãŸã€‚

ã„ãã¤ã‹ importance ã®å®šç¾©ãŒã‚ã‚‹ãŒã€ã“ã“ã§ã¯ `PredictionValuesChange` ã§å®šç¾©ã•ã‚Œã‚‹ã‚‚ã®ã«ã¤ã„ã¦ã¾ã¨ã‚ã‚‹ã€‚ã“ã‚Œã¯ãã® feature ãŒæœ€çµ‚çš„ãªäºˆæ¸¬å€¤ã«ã©ã‚Œã ã‘å½±éŸ¿ã‚’æŒã¤ã‹ã¨ã„ã†æŒ‡æ¨™ã§ã‚ã‚‹ã€‚

# CatBoost ã§ importance ã‚’å‡ºã—ã¦ã¿ã‚‹

ã¾ãšã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦å®Ÿéš›ã« feature importance ã‚’å‡ºåŠ›ã—ã¦ã¿ã‚‹ã€‚ã“ã“ã§ã¯ iris dataset ã‚’ä½¿ã„ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚

```python
from catboost import CatBoostClassifier, Pool
from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data, iris.target

model = CatBoostClassifier(iterations=1, depth=2, random_seed=42)

model.fit(X, y)
```

ã‚ã‚„ã‚ã‚’3ã‚¯ãƒ©ã‚¹ã«åˆ†ã‘ã‚‹åˆ†é¡å•é¡Œã‚’ã€æ·±ã•ãŒ2ã® tree ä¸€æœ¬ã§è§£ã„ã¦ã„ã‚‹ã€‚

ã“ã‚Œã‚’å®Ÿè¡Œã™ã‚‹ã¨çµæœã¨ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹

```python
model.plot_tree(tree_idx=0)
```
![](https://github.com/yng87/zenn-article/raw/master/images/tree_iris.png)

ã¾ãšã€ç‰¹å¾´é‡2ã®å€¤ã§åˆ†å²ã‚’ã—ã€ãã®å¾Œç‰¹å¾´é‡3ã®å€¤ã§åˆ†å²ã‚’ã—ã¦ã„ã‚‹æ§˜å­ãŒç¢ºèªã§ãã‚‹ã€‚CatBoost ã¯ä»–ã®GBDTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ç•°ãªã‚Šã€(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯) oblivious trees ã‚’ä½œæˆã™ã‚‹ã€‚ãã®ãŸã‚ã€åŒã˜æ·±ã•ã§ã¯å…¨ã¦ã®ãƒãƒ¼ãƒ‰ãŒåŒã˜æ¡ä»¶ã§åˆ†å²ã‚’è¡Œã†ã€‚

ã“ã“ã§ leaf ã«å…¥ã£ã¦ã„ã‚‹ `val` ãŒä½•è€…ã‹ï¼Ÿã¨ã„ã†ã“ã¨ã ãŒã€ä»Šè§£ã„ã¦ã„ã‚‹ã®ã¯3ã‚¯ãƒ©ã‚¹ã®åˆ†é¡ã§ã‚ã‚Šã€ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒã‚¯ãƒ©ã‚¹ $j$ ã«å±ã™ã‚‹ç¢ºç‡ã¯ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°

$$p(class = j) = \frac{\exp(a_{j})}{\sum_j \exp(a_{j})}$$

ã§è¡¨ã•ã‚Œã‚‹ã€‚CatBoostClassifier ãŒå‡ºåŠ›ã™ã‚‹ã®ã¯ã“ã® $a_{j}$ ã§ã‚ã‚‹ã€‚

ã“ã®ãƒ¢ãƒ‡ãƒ«ã® feature importance ã‚’è¦‹ã¦ã¿ã‚‹ã¨

```python
model.get_feature_importance(Pool(X, y), type="PredictionValuesChange")
```

```bash
array([ 0.        ,  0.        , 44.49955092, 55.50044908])
```

ã¨ãªã‚‹ã€‚æœ¨ã®åˆ†å²ã«ç‰¹å¾´é‡0ã¨1ãŒä½¿ã‚ã‚Œã¦ã„ãªã„ã®ã§ã€ãã‚Œã‚‰ã«é–¢ã—ã¦ã¯ã‚¼ãƒ­ã«ãªã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’ã¿ã‚‹ã¨ç‰¹å¾´é‡3ãŒç‰¹å¾´é‡2ã«æ¯”ã¹ã¦å°‘ã—ã ã‘é‡è¦ã§ã‚ã‚‹ã‚‰ã—ã„ã€‚
ã“ã®å®šç¾©ã«ã‚ˆã‚‹ importance ã¯è² ã«ãªã‚‰ãªã„ã®ã§ã€åˆè¨ˆ100ã«ãªã‚‹ã‚ˆã† normalize ã•ã‚ŒãŸå€¤ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã€‚

# CatBoost ã¯ä½•ã‚’è¨ˆç®—ã—ã¦ã„ã‚‹ã‹ï¼Ÿ


[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://catboost.ai/docs/concepts/fstr.html#fstr__regular-feature-importance)ã«ã‚ˆã‚‹ã¨ã€feature F ã® feature importance ã¯ leaf ã® ãƒšã‚¢ã«é–¢ã—ã¦ãã‚Œãã‚Œã®äºˆæ¸¬å€¤ã¨ãã®åŠ é‡å¹³å‡ã‚’æ¯”è¼ƒã—ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹

> Leaf pairs that are compared have different split values in the node on the path to these leaves. If the split condition is met (this condition depends on the feature F), the object goes to the left subtree; otherwise it goes to the right one.

$$importance_F=\sum_{tree, leafs_F} c_1(v_1 - avr)^2 + c_2(v_2 - avr)^2 \tag{1}$$

$c_1$, $c_2$ ã¯æ¯”è¼ƒã—ã¦ã„ã‚‹äºŒã¤ã® leaf node ãã‚Œãã‚Œã®æŒã¤ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆæœ¨ã‚’è¾¿ã£ã¦ãã® leaf ã«å±ã™ã‚‹ã“ã¨ã«ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ•°ï¼‰ã€$v_1$, $v_2$ ã¯ãã“ã§ã®äºˆæ¸¬å€¤ã®å€¤ (val) ã§ã‚ã‚‹ã€‚$avr$ ã¯ä»¥ä¸‹ã®ã‚ˆã†ãª $v_1$ ã¨ $v_2$ ã®åŠ é‡å¹³å‡ã§ã‚ã‚‹

$$avr = \frac{c_1v_1 + c_2 v_2}{c_1 + c_2}.$$

ã¤ã¾ã‚Šã€PredictionValuesChange ã«ã‚ˆã‚‹ feature importance ã¯ãã®ç‰¹å¾´é‡ã‚’ä½¿ã£ã¦åˆ†å²ã—ãŸå ´åˆã¨ã—ãªã‹ã£ãŸå ´åˆã§ã©ã‚Œãã‚‰ã„äºˆæ¸¬å€¤ãŒå¤‰ã‚ã‚‹ã‹ã¨ã„ã†æŒ‡æ¨™ã«ãªã£ã¦ã„ã‚‹ã€‚

æ¯”è¼ƒã«ä½¿ã† leaf pair ã¯ã©ã®ã‚ˆã†ã«é¸ã¹ã°è‰¯ã„ã®ã ã‚ã†ã‹ï¼Ÿã¾ãš leaf ç›´ä¸Šã®åˆ†å²ã«ä½¿ã‚ã‚Œã‚‹ç‰¹å¾´é‡ã«é–¢ã—ã¦ã¯ã‚ã‹ã‚Šã‚„ã™ã„ã€‚åŒã˜ parent ã‚’æŒã¤ leaf äºŒã¤ã‚’ä½¿ã£ã¦ $c_i$ ã¨ $v_i$ ã‚’è¨ˆç®—ã™ã‚Œã°è‰¯ã„ã€‚

ã§ã¯æœ¨ã®ã‚‚ã£ã¨ä¸Šã®æ–¹ã«ç¾ã‚Œã‚‹ç‰¹å¾´é‡ã«ã¤ã„ã¦ã¯ã©ã†ã™ã‚Œã°è‰¯ã„ã ã‚ã†ã‹ï¼Ÿä¸€èˆ¬ã®æœ¨ã§ã¯ leaf é–“ã®ãƒšã‚¢ã‚’å®šç¾©ã™ã‚‹ã“ã¨ã¯ã§ããªã•ãã†ã ãŒã€CatBoost ãŒç”Ÿæˆã™ã‚‹ oblivious tree ã«é™ã£ã¦ã¯ã†ã¾ãå®šç¾©ã§ãã‚‹ã€‚
ã¨ã„ã†ã®ã‚‚ã€æœ¨ã®å„æ·±ã•ã§åˆ†å²ã®æ¡ä»¶ãŒåŒä¸€ã¨ã„ã†ã“ã¨ã¯ã€çµå±€CatBoostã¯å˜ã«åˆ†å²æ¡ä»¶ã‚’ä¸€åˆ—ã«ä¸¦ã¹ã¦ Yes/No ã®åˆ¤å®šã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ã‚‹ã«éããªã„ã€‚ãªã®ã§ã€d ç•ªç›®ã®åˆ†å²ãŒç•°ãªã‚Šã€ãã®å‰å¾Œã®åˆ†å²ã¯å…¨ã¦åŒã˜ã‚ˆã†ãª leaf node ã®ãƒšã‚¢ã‚’å¿…ãšä½œã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãã®ã‚ˆã†ãªãƒšã‚¢ã‚’é›†ã‚ã¦ãã¦ä¸Šã® (1) å¼ã§æ·±ã• d ç•ªç›®ã®feature ã®importance ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ããã†ã ã€‚

ä»¥ä¸Šã®ã“ã¨ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã ã¨ã‚ã‹ã‚Šã¥ã‚‰ã„ãŒã€[ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®è©²å½“ç®‡æ‰€](https://github.com/catboost/catboost/blob/49e24bba3279ae1ac22146b8322e37d86e6049bf/catboost/libs/fstr/feature_str.h#L218-L256)ã‚’è¦‹ã‚‹ã¨å¤šåˆ†ãã†ã ã‚ã†ã¨æƒ³åƒã§ãã‚‹ã€‚[^1]

# å®Ÿéš›ã«è¨ˆç®—ã—ã¦ç¢ºã‹ã‚ã¦ã¿ã‚‹

ä»Šã®èª¬æ˜ã‚’å®Ÿéš›ã«å…ˆã»ã©è¨ˆç®—ã—ãŸ iris ã®ä¾‹ã§ç¢ºã‹ã‚ã¦ã¿ã‚‹ã€‚[^2] leaf node ã‚’å·¦ã‹ã‚‰ leaf0, leaf1, ..., leaf3 ã¨å‘¼ã¶ã“ã¨ã«ã™ã‚‹ã€‚ã¾ãš leaf ç›´ä¸Šã®åˆ†å²ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ feature 3 ã«ã¤ã„ã¦ã¯ã€(leaf0, leaf1) ã¨ (leaf2, leaf3) ã«é–¢ã—ã¦ãã‚Œãã‚Œ (1) å¼ã‚’è¨ˆç®—ã™ã‚‹

```python
# get border values for each feature
borders = model.get_borders() 
# {0: [], 1: [], 2: [4.949999809265137], 3: [0.44999998807907104]}

# get samples in each leaf node
leaf_samples = []
leaf_samples.append(X[(X[:, 2] <= borders[2][0]) & (X[:, 3] <= borders[3][0])])
leaf_samples.append(X[(X[:, 2] <= borders[2][0]) & (X[:, 3] > borders[3][0])])
leaf_samples.append(X[(X[:, 2] > borders[2][0]) & (X[:, 3] <= borders[3][0])])
leaf_samples.append(X[(X[:, 2] > borders[2][0]) & (X[:, 3] > borders[3][0])])

[s.shape[0] for s in leaf_samples] # [48, 56, 0, 46]

# get leaf values
vals = model.get_leaf_values().reshape(4, 3)
#
# array([[ 0.84210526, -0.42105263, -0.42105263],
#        [-0.38461538,  0.67692308, -0.29230769],
#        [ 0.        ,  0.        ,  0.        ],
#        [-0.41818182, -0.36363636,  0.78181818]])

ftr_imp = np.zeros(4)
feature_idx = 3

for i1, i2 in [(0, 1), (2, 3)]:
  # weight
  c1 = leaf_samples[i1].shape[0]
  c2 = leaf_samples[i2].shape[0]
  c_sum = c1 + c2

  # compute values difference
  for j in range(3):
    v1 = vals[i1][j]
    v2 = vals[i2][j]

    avg_v = (c1*v1 + c2*v2) / c_sum
    diff = c1*(v1 - avg_v)**2+ c2*(v2 - avg_v)**2

    ftr_imp[feature_idx] += diff

ftr_imp
```

çµæœ

```bash
array([ 0.        ,  0.        ,  0.        , 70.48167229])
```

æ¬¡ã«ã€root node ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ feature 2 ã«ã¤ã„ã¦è¨ˆç®—ã™ã‚‹ã€‚ã“ã“ã§ãƒšã‚¢ã‚’çµ„ã‚€ã®ã¯ (leaf0, leaf2), (leaf1, leaf3) ã§ã‚ã‚‹ã€‚ä¾‹ãˆã°ã€leaf0 ã¨ leaf2 ã¯ã€faeture 3 ã«é–¢ã™ã‚‹åˆ†å²ã¯ä¸¡æ–¹ No ã ãŒã€root ã§ã® feature 2 ã«é–¢ã™ã‚‹åˆ†å²ã¯ç•°ãªã‚‹ã€‚

```python
feature_idx = 2

for i1, i2 in [(0, 2), (1, 3)]:
  c1 = leaf_samples[i1].shape[0]
  c2 = leaf_samples[i2].shape[0]
  c_sum = c1 + c2

  for j in range(3):
    v1 = vals[i1][j]
    v2 = vals[i2][j]

    avg_v = (c1*v1 + c2*v2) / c_sum
    diff = c1*(v1 - avg_v)**2+ c2*(v2 - avg_v)**2

    ftr_imp[feature_idx] += diff

ftr_imp
```

çµæœã¯

```bash
array([ 0.        ,  0.        , 56.51130428, 70.48167229])
```

æœ€å¾Œã«ã“ã‚Œã‚’åˆè¨ˆ100%ã«ãªã‚‹ã‚ˆã† normalize ã™ã‚‹ã¨

```bash
array([ 0.        ,  0.        , 44.49955092, 55.50044908])
```

ã¨ãªã‚‹ã€‚ã“ã‚Œã¯CatBoost ã® APIã‚’ä½¿ã£ã¦æ±‚ã‚ãŸçµæœã«ä¸€è‡´ã—ã¦ã„ã‚‹ã€‚ã‚ˆã‚Šè¤‡é›‘ãªæœ¨ã«ãªã£ãŸæ™‚ã‚‚åŒæ§˜ã«è¨ˆç®—ã§ãã‚‹ã¯ãšã§ã‚ã‚‹ã€‚

# Non-oblivious tree ã®å ´åˆ

ä¸€èˆ¬ã®å¯¾ç§°ã§ã¯ãªã„æœ¨ã®å ´åˆã¯ä¸Šè¨˜ã®æ–¹æ³•ã¯ä½¿ãˆãªã„ã€‚CatBoost ã¯ oblivious ã®åˆ¶é™ã‚’ä»˜ã‘ãšã«å­¦ç¿’ã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ãŒã€ãã®éš›ã® importance ã¯

1. leaf node ã® parent ã«å¯¾ã—ã¦ (1) å¼ã§ feature F ã® importance ã‚’è¨ˆç®—
2. ãã® leaf node ã‚’å‰Šé™¤ã—ã€parent ã ã£ãŸ node ã‚’æ–°ãŸã« leaf ã¨ã™ã‚‹ã€‚ãã‚Œã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ $c_1 + c_2$ã§ã€val ã¯ $avr$ ã§å‰²ã‚Šå½“ã¦ã‚‹

ã¨ã„ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦è¨ˆç®—ã•ã‚Œã‚‹ã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚‹ importance ã¯ oblivious tree ã«å¯¾ã—ã¦è¨ˆç®—ã•ã‚ŒãŸå€¤ã¨ã¯ä¸€èˆ¬ã«ä¸€è‡´ã—ãªã„ã€‚
[è©³ã—ãã¯ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®è©²å½“ç®‡æ‰€](https://github.com/catboost/catboost/blob/49e24bba3279ae1ac22146b8322e37d86e6049bf/catboost/libs/fstr/feature_str.h#L132-L216)ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã€‚

ä¸Šã§ä½¿ã£ãŸ iris ã®ãƒ¢ãƒ‡ãƒ«ã§å®Ÿéš›ã«è¨ˆç®—ã—ã¦ã¿ã‚ˆã†ã€‚
ã¾ãšã¯ leaf ã«ã¤ã„ã¦
```python
ftr_imp = np.zeros(4)

parent_vals = np.zeros((2, 3))
parent_weight = np.zeros(2)

for i in range(0, 4, 2):
  c1 = leaf_samples[i].shape[0]
  c2 = leaf_samples[i+1].shape[0]
  c_sum = c1 + c2

  parent_weight[i // 2] = c_sum

  for j in range(3):
    v1 = vals[i][j]
    v2 = vals[i+1][j]

    avg_v = (c1*v1 + c2*v2) / c_sum
    diff = c1*(v1 - avg_v)**2+ c2*(v2 - avg_v)**2

    ftr_imp[3] += diff

    parent_vals[i // 2][j] = avg_v
```
ãã—ã¦ root ã«ã¤ã„ã¦
```python
c1 = parent_weight[0]
c2 = parent_weight[1]
c_sum = c1 + c2

for j in range(3):
  v1 = parent_vals[0][j]
  v2 = parent_vals[1][j]
  avg_v = (c1*v1 + c2*v2) / c_sum
  diff = c1*(v1 - avg_v)**2 + c2*(v2 - avg_v)**2

  ftr_imp[2] += diff

ftr_imp / sum(ftr_imp) * 100
```
çµæœã¯
```bash
array([ 0.        ,  0.        , 46.61367922, 53.38632078])
```
ã¨ãªã‚Šã€ç¢ºã‹ã« oblivious ã®æ™‚ã¨ã¯ç•°ãªã‚‹å€¤ã«ãªã‚‹ã€‚

[^1]: éƒ¨åˆ†çš„ã«ã‚½ãƒ¼ã‚¹ã‚’çœºã‚ãŸã ã‘ãªã®ã§å‹˜é•ã„ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒâ€¦
[^2]: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯: https://colab.research.google.com/drive/1CiRm_vby9S4c_q5dWq_oY88hSehC17_U?usp=sharing
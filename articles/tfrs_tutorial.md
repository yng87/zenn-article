---
title: "CatBoost ã® feature importance"
emoji: "ğŸˆ" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["æ©Ÿæ¢°å­¦ç¿’"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: false # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

å°‘ã—å‰ã«ã€Tensorflow Recommenders (TFRS) ã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ã„ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€Keras ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚‹ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚ˆã†ã§ã™ã€‚

[https://www.tensorflow.org/recommenders:embed:cite]

è¿‘å¹´ã¯æ·±å±¤å­¦ç¿’ã‚’ç”¨ã„ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿå¿œç”¨ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ãã¾ã—ãŸã€‚ç‰¹ã«ã€YouTube ã«ä»£è¡¨ã•ã‚Œã‚‹ã‚ˆã†ãªå¤§è¦æ¨¡ãªãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã§ã¯ã€2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã¨å‘¼ã°ã‚Œã‚‹å½¢ã§ã®åˆ©ç”¨ãŒã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã«ãªã£ã¦ã„ã¾ã™((https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45530.pdf))ã€‚ã“ã®TFRSã¯ã€2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’å¿µé ­ã«ä½œã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚

ã¨ã„ã†ã“ã¨ã§TFRSã‚’ä½¿ã£ã¦ã€2-stage ã®æ·±å±¤æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ãƒ»è©•ä¾¡ã‚’ã—ã¦ã¿ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€TFRSã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ã‚‚å‡ºã¦ãã¦ã„ã‚‹ã€Movielens 100k ã§ã™ã€‚ã“ã‚Œãã‚‰ã„ã ã¨ Google colaboratory ã§ã‚‚æ°—è»½ã«å®Ÿè¡Œã§ãã¾ã™ã€‚

# 2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã¨ã¯
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã« engagement ãŒé«˜ããªã‚‹ã‚ˆã†ãªã‚¢ã‚¤ãƒ†ãƒ ã‚’æç¤ºã™ã‚‹ã“ã¨ã§ã™ã€‚ãã®ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®äººæ°—ã‚’å­¦ç¿’ã•ã›ã€ã§ããŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã‚¢ã‚¤ãƒ†ãƒ ã«ã‚¹ã‚³ã‚¢ã‚’ã¤ã‘ã¾ã™ã€‚ãã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¢ã‚¤ãƒ†ãƒ ãŒæ¨è–¦ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

ã“ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã§è¡Œã†ã®ã¯å¤§å¤‰ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«å…¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸã‚½ãƒ¼ãƒˆãŒå¿…è¦ãªãŸã‚ã€å¯¾è±¡ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¤šããªã‚‹ã»ã©è¨ˆç®—é‡ãŒå¢—ãˆã¾ã™ã€‚ä¾‹ãˆã° YouTube ã‚„ Twitter ã®ã‚ˆã†ãªå¤§è¦æ¨¡ãªã‚·ã‚¹ãƒ†ãƒ ã§ã“ã‚Œã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¡Œã†ã®ã¯ latency ã®è¦³ç‚¹ã§è¨±å®¹ã•ã‚Œãªã„ã§ã—ã‚‡ã†ã€‚
ã‚ã‚‰ã‹ã˜ã‚ãƒãƒƒãƒã§å‡¦ç†ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã—ã¦ãŠãã¨ã„ã†æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ãŒã€ç‰¹å¾´é‡ã®æ¬¡å…ƒãŒå¤šããªã‚‹ã»ã©ï¼ˆä¾‹ãˆã°ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®ä»–ã«ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æŒã¤å ´åˆãªã©ï¼‰è†¨å¤§ãªå®¹é‡ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªæƒ…å ±ã‚’ä½¿ã†ã“ã¨ãŒã§ããªããªã‚Šã¾ã™ã€‚

ã“ã‚Œã‚’è§£æ±ºã™ã‚‹æ–¹æ³•ãŒ 2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã§ã™ã€‚åå‰ã®é€šã‚ŠäºŒæ®µéšã®ã‚·ã‚¹ãƒ†ãƒ ã«ãªã£ã¦ã„ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹æˆã‚’å–ã‚Šã¾ã™

1. Candidate generation: ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‘ã‚¹å…¨ä½“ã‹ã‚‰ã€ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã«å¿œã˜ãŸé–¢é€£ã‚¢ã‚¤ãƒ†ãƒ  (candidates) ã‚’æ•°åã‹ã‚‰æ•°ç™¾å–å¾—ã™ã‚‹ã€‚é€Ÿåº¦é‡è¦–ã€‚
2. Re-ranking: Candidates ã‚’ã‚ˆã‚Šç²¾ç·»ãªãƒ¢ãƒ‡ãƒ«ã§ãƒ©ãƒ³ã‚¯ã¥ã‘ã™ã‚‹ã€‚è³ªé‡è¦–ã€‚

Candidate generation ã«ç”¨ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ retrieval model ã¨å‘¼ã°ã‚Œã€æ•°ç™¾ä¸‡ã‚„æ•°åå„„ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰å°‘æ•°ã®é–¢é€£ã‚¢ã‚¤ãƒ†ãƒ ã‚’æŠ½å‡ºã™ã‚‹ã®ã«ä½¿ã‚ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯é«˜é€Ÿã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã€ãã®ä»£å„Ÿã¨ã—ã¦å¤šå°‘è³ªã¯è½ã¡ã‚‹ã“ã¨ã‚’è¨±å®¹ã—ã¾ã™ã€‚ãã®å¾Œå–å¾—ã—ãŸ candidates ã‚’å¾Œç¶šã® ranking model ãŒãƒ©ãƒ³ã‚¯ã¥ã‘ã—ã¾ã™ã€‚Retrieval model ã¯é«˜é€Ÿãªä»£ã‚ã‚Šã«ç„¡é–¢ä¿‚ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚‚æ¨è–¦ã—ã¦ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€ranking model ãŒãã®ã‚ˆã†ãªã‚‚ã®ã‚’è½ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã«é–¢é€£ã™ã‚‹ã‚ˆã†ãªã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¸Šä½ã«æŒã£ã¦ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

ã“ã®2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã¯å¤§è¦æ¨¡ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªæ¨è«–ã‚’è¡Œã†ã«ã¯å¿…é ˆã§ã€YouTubeã€Twitter((https://irsworkshop.github.io/2020/publications/paper_2_%20Virani_Twitter.pdf))ã€Pinterest((http://arxiv.org/abs/1702.07969)) ãªã©å¤šãã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

# å®Ÿè£…

2-stage ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã¨è¨€ã£ã¦ã‚‚å¿…ãšã—ã‚‚ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ã†å¿…è¦ã¯ãªãã€å®Ÿéš›Pinterestãªã©ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ãŒã€ã“ã“ã¯Googleã«å€£ã£ã¦DNNã§ã®å®Ÿè£…ã‚’è©¦ã—ã¾ã™ã€‚
è©¦ã™ã¨è¨€ã£ã¦ã‚‚ã€[TFRSã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ç¾¤](https://www.tensorflow.org/recommenders/examples/quickstart)ã‚’ã»ã¼ã‚³ãƒ”ãƒšã—ã¦ã„ã‚‹ã ã‘ã§ã™ã€‚è©³ã—ã„ã“ã¨ã¯ãã¡ã‚‰ã‚’è¦‹ã¦ãã ã•ã„ã€‚å¾Œã§æ›¸ãè©•ä¾¡ã®éƒ¨åˆ†ã ã‘ã¯æ–°ã—ã„ã§ã™ã€‚
ã‚³ãƒ¼ãƒ‰ã¯ [Colaboratory](https://colab.research.google.com/drive/1fP43e95Uf-kQmvnJ4Mt3nWd1eYtXZ9M9?usp=sharing) ã«ã‚ã‚Šã¾ã™ã€‚

## æº–å‚™

ã¾ãšå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
```python
!pip install -q tensorflow-recommenders
!pip install -q --upgrade tensorflow-datasets

import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_recommenders as tfrs
```

ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã¯ Movielens 100k ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå„æ˜ ç”»ã«ã¤ã‘ãŸ1-5ç‚¹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒ100,000ä»¶å…¥ã£ã¦ã„ã¾ã™ã€‚
ã“ã“ã§ã¯ã€1-3ç‚¹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è² ä¾‹ã€4-5ç‚¹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ­£ä¾‹ã¨ã—ã¦æ‰±ã†ã“ã¨ã«ã—ã¾ã™ã€‚
ã¾ãŸç‰¹å¾´é‡ã¨ã—ã¦ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã® timestamp ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚
```python
ratings = tfds.load("movielens/100k-ratings", split="train")
movies = tfds.load("movielens/100k-movies", split="train")

ratings = ratings.map(lambda x: {
    "movie_title": x["movie_title"],
    "user_id": x["user_id"],
    "timestamp": x["timestamp"],
    "user_pref": 1 if x["user_rating"]>=4 else 0,
})
movies = movies.map(lambda x: x["movie_title"])
```

ãƒ‡ãƒ¼ã‚¿ã‚’ train/test split ã—ã¾ã™ã€‚
```python
tf.random.set_seed(42)
shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)

train = shuffled.take(80_000)
test = shuffled.skip(80_000).take(20_000)

cached_train = train.shuffle(100_000).batch(2048)
cached_test = test.batch(4096).cache()
```

ç‰¹å¾´é‡ä½œæˆã«å¿…è¦ãªä¸‹æº–å‚™ã‚’ã—ã¾ã™ã€‚
ã“ã®å¾Œã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã® embedding ã‚’å¤šç”¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€ãã®ãŸã‚ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã®ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
timestamp ã‚‚å˜ãªã‚‹æ•´æ•°å€¤ã§ã¯ãªã 1000 å€‹ã®ãƒã‚±ãƒƒãƒˆã«åˆ†ã‘ã¦æ‰±ã„ã€ã‚„ã¯ã‚Š embed ã—ã¾ã™ã€‚ã“ã®è¾ºã¯ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãã®ã¾ã¾ã§ã™ã€‚

```python
timestamps = np.concatenate(list(ratings.map(lambda x: x["timestamp"]).batch(100)))

max_timestamp = timestamps.max()
min_timestamp = timestamps.min()

timestamp_buckets = np.linspace(
    min_timestamp, max_timestamp, num=1000,
)

unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))
unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(
    lambda x: x["user_id"]))))
```

## Retrieval model
ã¾ãšã¯ã€candidate generation ç”¨ã® retrieval model ã‚’ä½œæˆã—ã¾ã™ã€‚
Retrieval model ã¯ two-tower model ã¨ã‚‚è¨€ã‚ã‚Œã€queryï¼ˆuser_id ã¨ timestampï¼‰ã¨ candidate (movie) ãã‚Œãã‚Œã§ç‹¬ç«‹ã—ãŸã€multi-layer perceptron (MLP) ã‚’ä½œæˆã—ã¾ã™ã€‚
Query tower ã¨ candidate tower ã‹ã‚‰ãã‚Œãã‚ŒåŒã˜æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã—ã€ãã‚Œã‚‰ã® similarity ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒ­ã‚¹é–¢æ•°ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
æ¨è«–æ™‚ã«ã¯ãƒ­ã‚¹ã‚’è¨ˆç®—ã›ãšã€query tower ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã«é¡ä¼¼ã—ã¦ã„ã‚‹ candidate ã‚’å–å¾—ã™ã‚Œã°è‰¯ã„ã®ã§ã€è¿‘ä¾è¿‘å‚æ¢ç´¢ãªã©ã‚’ä½¿ã£ã¦é«˜é€Ÿã«æ¨è«–ãŒã§ãã¾ã™ã€‚

ã¾ãšã‚¯ã‚¨ãƒªã®æƒ…å ±ã‚’ embed ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Šã¾ã™ã€‚æ™®é€šã® keras ã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã“ã§ã¯ user_id ã¨ timestamp ã®æƒ…å ±ã‚’ concat ã—ã¦ã„ã¾ã™ã€‚

```python

class UserModel(tf.keras.Model):

    def __init__(self):
        super().__init__()

        self.user_embedding = tf.keras.Sequential([
            tf.keras.layers.experimental.preprocessing.StringLookup(
                vocabulary=unique_user_ids, mask_token=None),
            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),
        ])
        self.timestamp_embedding = tf.keras.Sequential([
            tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),
            tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),
        ])
        self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()

        self.normalized_timestamp.adapt(timestamps)

    def call(self, inputs):
        return tf.concat([
            self.user_embedding(inputs["user_id"]),
            self.timestamp_embedding(inputs["timestamp"]),
            self.normalized_timestamp(inputs["timestamp"]),
        ], axis=1)
```
ã“ã®ä¾‹ã§è¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã€DNNã§ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹éš›ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®IDã® embedding ã‚’å¤šç”¨ã—ã¾ã™ã€‚

ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§å¾—ã‚‰ã‚ŒãŸ embedding ãƒ™ã‚¯ãƒˆãƒ«ã‚’MLPã«é€šã—ã¾ã™ã€‚å‰çµåˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ§‹æˆã¯å¤–ã‹ã‚‰æŒ‡å®šã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã§ query tower ã®å®Œæˆã§ã™ã€‚

```python
class QueryModel(tf.keras.Model):

    def __init__(self, layer_sizes):
        super().__init__()

        self.embedding_model = UserModel()
        self.dense_layers = tf.keras.Sequential()
        for layer_size in layer_sizes[:-1]:
            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation="relu"))

        for layer_size in layer_sizes[-1:]:
            self.dense_layers.add(tf.keras.layers.Dense(layer_size))

    def call(self, inputs):
        feature_embedding = self.embedding_model(inputs)
        return self.dense_layers(feature_embedding)
```

åŒæ§˜ã®ã“ã¨ã‚’ã‚¢ã‚¤ãƒ†ãƒ  (candidate) å´ã§ã‚‚è¡Œã„ã¾ã™ã€‚ã“ã“ã§ã¯æ˜ ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«ã® embed ã¨ ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ã® vectorization ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚
```python
class MovieModel(tf.keras.Model):

    def __init__(self):
        super().__init__()

        max_tokens = 10_000

        self.title_embedding = tf.keras.Sequential([
          tf.keras.layers.experimental.preprocessing.StringLookup(
              vocabulary=unique_movie_titles,mask_token=None),
          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)
        ])

        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(
            max_tokens=max_tokens)

        self.title_text_embedding = tf.keras.Sequential([
          self.title_vectorizer,
          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),
          tf.keras.layers.GlobalAveragePooling1D(),
        ])

        self.title_vectorizer.adapt(movies)

    def call(self, titles):
        return tf.concat([
            self.title_embedding(titles),
            self.title_text_embedding(titles),
        ], axis=1)
```

Candidate ã® embedding ã‚’MLPã«é€šã›ã° candidate tower ã®å®Œæˆã§ã™ã€‚
```python
class CandidateModel(tf.keras.Model):

    def __init__(self, layer_sizes):
        super().__init__()

        self.embedding_model = MovieModel()
        self.dense_layers = tf.keras.Sequential()
        
        for layer_size in layer_sizes[:-1]:
            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation="relu"))
            
        for layer_size in layer_sizes[-1:]:
            self.dense_layers.add(tf.keras.layers.Dense(layer_size))

    def call(self, inputs):
        feature_embedding = self.embedding_model(inputs)
        return self.dense_layers(feature_embedding)
```

ä»¥ä¸ŠäºŒã¤ã® tower ã‹ã‚‰å–å¾—ã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ã£ã¦ãƒ­ã‚¹ã‚’è¨ˆç®—ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚
```python
class MovielensRetrievalModel(tfrs.models.Model):

    def __init__(self, layer_sizes):
        super().__init__()
        self.query_model = QueryModel(layer_sizes)
        self.candidate_model = CandidateModel(layer_sizes)
        self.task = tfrs.tasks.Retrieval(
            metrics=tfrs.metrics.FactorizedTopK(
                candidates=movies.batch(128).map(self.candidate_model),
            ),
        )

    def compute_loss(self, features, training=False):
        query_embeddings = self.query_model({
            "user_id": features["user_id"],
            "timestamp": features["timestamp"],
        })
        movie_embeddings = self.candidate_model(features["movie_title"])

        return self.task(
            query_embeddings, movie_embeddings, compute_metrics=not training)
```
ã“ã“ã§ã¯ `tfrs.models.Model` ã‚’ç¶™æ‰¿ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ç”¨ã«ã€keras ã®ãƒ¢ãƒ‡ãƒ«ã‚’è–„ãæ‹¡å¼µã—ãŸã‚‚ã®ã§ã™ã€‚å®Ÿéš›ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ã‚‚ã‚ã‚‹é€šã‚Šã€åŒã˜å‡¦ç†ã‚’ tfrs ã‚’ä½¿ã‚ãšã«æ›¸ãã“ã¨ã‚‚ç°¡å˜ã§ã™ã€‚
ã¾ãŸã€ã“ã“ã§TFRSç‰¹æœ‰ã® `tfrs.tasks.Retrieval` ã¨ã„ã†ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒç™»å ´ã—ã¾ã™ã€‚è¦ã¯ãƒ­ã‚¹é–¢æ•°ã‚’å®šç¾©ã—ã¦ã„ã‚‹ã‚ã‘ã§ã™ãŒã€retrieval ãƒ¢ãƒ‡ãƒ«ã‚’æƒ³å®šã—ã¦ã€query ã¨ candidate ã® embedding ã‚’å…¥åŠ›ã¨ã™ã‚‹ã‚ˆã†ãªå½¢ã®ã‚‚ã®ãŒä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚Query ã¨ candidate ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ concat ã—ã¦ã•ã‚‰ã«å…¨çµåˆå±¤ã«é€šã—ãŸã‚Šãªã©ã¯ã—ã¦ã„ãªã„ã“ã¨ãŒé‡è¦ã§ã™ã€‚å†…éƒ¨ã§ã¯äºŒã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ï¼‰ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‹ã‚‰ãƒ­ã‚¹ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚

ã“ã“ã®ãƒ­ã‚¹ã®èª¬æ˜ãŒãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ã¯ãªã„ã®ã§ã€å°‘ã—èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸ((ä¾‹ãˆã° [ã“ã®è«–æ–‡](https://dl.acm.org/doi/10.1145/3298689.3346996)ã®3ç« ãªã©))ã€‚æ­£å¼åç§°ãŒã‚ã‚‹ã®ã‹ã‚ã‹ã‚Šã¾ã›ã‚“ãŒ in-batch softmax ãªã©ã©å‘¼ã°ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚
ãƒŸãƒ‹ãƒãƒƒãƒã®å„ã‚µãƒ³ãƒ—ãƒ« `(query, candidate)` ã«ã¤ã„ã¦ã€query ã«å¯¾å¿œã™ã‚‹ candidate ãŒæ­£è§£ã‚¯ãƒ©ã‚¹ã€ãã‚Œä»¥å¤–ã®ãƒŸãƒ‹ãƒãƒƒãƒå†…ã® candidate ãŒä¸æ­£è§£ã‚¯ãƒ©ã‚¹ã«ãªã‚Šã¾ã™ã€‚å¼ã§æ›¸ãã¨
<div>[tex:
P(y_i|x_i) = \frac{\exp(x_i^Ty_i)}{\sum_j \exp(x_i^Ty_j)} \\
L = -\frac{1}{|B|} \sum_{i\in B} \log P(x_i|y_i)
]</div>
ã¨ãªã‚Šã¾ã™ã€‚[ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰](https://github.com/tensorflow/recommenders/blob/v0.3.0/tensorflow_recommenders/tasks/retrieval.py#L89-L161)ã‚’èª­ã‚€ã¨å¤šåˆ†ã“ã‚“ãªæ„Ÿã˜ã«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ï¼‰ãªã£ã¦ã„ã¾ã™ã€‚x, y ã¯ãã‚Œãã‚Œ query ã¨ candidate ã®ãã‚Œãã‚Œã® tower ã‚’é€šã—ãŸå¾Œã® embedding ãƒ™ã‚¯ãƒˆãƒ«ã§ã™ã€‚é–¢é€£ã®ã‚ã‚‹ query ã¨ candidate ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ããªã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã™ã€‚



ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã™ã€‚æ³¨æ„ç‚¹ã¨ã—ã¦ã€ã“ã“ã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ˜ ç”»ã«å¯¾ã™ã‚‹ rating ã®æƒ…å ±ã¯ä½¿ã£ã¦ã„ã¾ã›ã‚“ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ã‚‹æ˜ ç”»ã‚’è¦‹ãŸæ™‚ç‚¹ã§ãã®æ˜ ç”»ã® relevance ã¯è¦‹ãªã‹ã£ãŸã‚‚ã®ã‚ˆã‚Šé«˜ã„ã¯ãšã§ã™ã€‚è¦‹ãŸå¾Œã«æ°—ã«ã„ã‚‹ã‹ã©ã†ã‹ã¯å¾Œç¶šã® ranking model ã«åˆ¤æ–­ã•ã›ã‚‹ã“ã¨ã«ã—ã¦ã€ã“ã“ã§ã¯ã¨ã«ã‹ããƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ãŸæ˜ ç”»ã¯å…¨ã¦ãƒã‚¸ãƒ†ã‚£ãƒ–ã ã¨æ€ã†ã“ã¨ã«ã—ã¾ã™ã€‚

```python
num_epochs = 100

ret_model = MovielensRetrievalModel([64, 32])
ret_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))

two_layer_history = ret_model.fit(
    cached_train,
    validation_data=cached_test,
    validation_freq=10,
    epochs=num_epochs,
    verbose=0,
)

accuracy = two_layer_history.history["val_factorized_top_k/top_100_categorical_accuracy"][-1]
print(f"Top-100 accuracy: {accuracy:.2f}.")
>>> 0.28
```
ãƒˆãƒƒãƒ—100ã®accuracy ã¯ 0.28 ã«ãªã‚Šã¾ã—ãŸã€‚100æœ¬æ˜ ç”»ã‚’æ¨è–¦ã—ãŸã‚‰ã€å¹³å‡28æœ¬ã¯å®Ÿéš›ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã‚‹ã‚‚ã®ã«ãªã‚Šã¾ã™ã€‚

ä»¥ä¸Šã§ retrieval model ãŒã§ããŸã®ã§ã€è¿‘å‚æ¢ç´¢ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã«ã‚ˆã£ã¦å…¥åŠ›ã‚¯ã‚¨ãƒªã® embedding ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ã€é¡ä¼¼åº¦ã®é«˜ã„ candidate ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
cand_index = tfrs.layers.factorized_top_k.BruteForce(ret_model.query_model, k=100)
cand_index.index(movies.batch(100).map(ret_model.candidate_model), movies)
```
ã“ã“ã§ã¯ç°¡å˜ã®ãŸã‚ã« `tfrs.layers.factorized_top_k.BruteForce` ã¨ã„ã†å³å¯†ãªè¿‘å‚æ¢ç´¢ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€å®Ÿéš›ã«ãƒ¢ãƒ‡ãƒ«ã‚’ serving ã™ã‚‹ã¨ãã«ã¯é«˜é€Ÿãªè¿‘ä¼¼è¿‘å‚æ¢ç´¢ã‚’ä½¿ã†ã“ã¨ã«ãªã‚‹ã¯ãšã§ã™ã€‚

## Ranking model
ç¶šã„ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã“ã§ã¯ retrieval model ã¨é•ã£ã¦ã€query ã¨ candidate ã® embedding ãƒ™ã‚¯ãƒˆãƒ«ã‚’ concat ã—ã¦å…¨çµåˆå±¤ã«é€šã—ã¾ã™ã€‚
Retrieval ãƒ¢ãƒ‡ãƒ«ã§ã¯å˜ãªã‚‹ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®éƒ¨åˆ†ã—ã‹å­¦ã¹ã¾ã›ã‚“ã§ã—ãŸãŒã€ã“ã“ã§ã¯ã‚ˆã‚Šãƒªãƒƒãƒãªç‰¹å¾´ã‚’å­¦ç¿’ã«ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã¯ãšã§ã™ã€‚
ã¾ãŸã€ã“ã“ã§ã¯ rating ã‚’ï¼ˆåˆã‚ã«è¿°ã¹ãŸã‚ˆã†ã« 0 or 1 ã«å¤‰æ›ã—ãŸã‚‚ã®) å­¦ç¿’ã—ã¾ã™ã€‚

```python
class RankingModel(tf.keras.Model):

    def __init__(self):
        super().__init__()
        embedding_dimension = 32

        self.user_embeddings = UserModel()
        self.movie_embeddings = MovieModel()

        self.ratings = tf.keras.Sequential([
          tf.keras.layers.Dense(256, activation="relu"),
          tf.keras.layers.Dense(64, activation="relu"),
          tf.keras.layers.Dense(1, activation='sigmoid')
        ])

    def call(self, inputs):

        user_embedding = self.user_embeddings({
            "user_id": inputs["user_id"],
            "timestamp": inputs["timestamp"],
        })
        movie_embedding = self.movie_embeddings(inputs["movie_title"])

        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))
```

ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’å…ƒã«ã€TFRSã® ranking model ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã®éƒ¨åˆ†ã¯æ™®é€šã® binary classification ã§ã™ã€‚
```python
class MovielensRankingModel(tfrs.models.Model):

    def __init__(self):
        super().__init__()
        self.ranking_model = RankingModel()
        self.task = tfrs.tasks.Ranking(
            loss = tf.keras.losses.BinaryCrossentropy(),
            metrics=[tf.keras.metrics.BinaryAccuracy()]
        )

    def compute_loss(self, features, training=False):
        rating_predictions = self.ranking_model({
            "user_id": features["user_id"],
            "timestamp": features["timestamp"],
            "movie_title": features["movie_title"]
        })

        return self.task(labels=features["user_pref"], predictions=rating_predictions)
```

å­¦ç¿’ã‚’ã—ã¾ã™ã€‚å¤§ä½“ validation ã‚»ãƒƒãƒˆã® accuracy ãŒ 0.7 ãã‚‰ã„ã«ãªã£ã¦ã„ã¾ã—ãŸã€‚
```python
num_epochs = 100

ranking_model = MovielensRankingModel()
ranking_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))

ranking1_history = ranking_model.fit(
    cached_train,
    validation_data=cached_test,
    validation_freq=10,
    epochs=num_epochs,
    verbose=1,
)
```

# è©•ä¾¡

ä»¥ä¸Šã§ä½œæˆã—ãŸ 2-stage ãƒ¢ãƒ‡ãƒ«ãŒä¸Šæ‰‹ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºã‹ã‚ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ãªæ‰‹é †ã§è©•ä¾¡ã—ã¾ã™

* `test` ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ­£ä¾‹ã ã‘ã‚’å–ã‚‹ã€‚å„ `(user_id, timestamp)` ãŒã‚¯ã‚¨ãƒªã§å¯¾å¿œã™ã‚‹ `movie_title` ãŒ ground truth
* å„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€10ä»¶ã® candidate generation ã‚’è¡Œã†
* ãã‚Œã‚‰ã‚’ã€ranking model ã‚’ä½¿ã£ã¦ä¸¦ã³æ›¿ãˆã‚‹
* ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å‰å¾Œã®æ¨è–¦ãƒªã‚¹ãƒˆã‚’ nDCG ã§è©•ä¾¡

ã‚‚ã— serving ã«ä½¿ã†ãªã‚‰ candidate generation ã¯100ä»¶ãªã©ã‚‚ã£ã¨å¤šãã‚„ã£ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã„ã¾ã™ãŒã€ã“ã“ã§ã¯ã‚ãã¾ã§è©•ä¾¡ç”¨ã«10ä»¶ã«ç•™ã‚ã¦ã€ãã®10ä»¶ã®ä¸­ã§ ranking model ãŒæ­£è§£ã‚’ã‚ˆã‚Šä¸Šä½ã«æŒã£ã¦æ¥ã‚Œã‚‹ã‹ã©ã†ã‹ã‚’è¦‹ã‚‹ã“ã¨ã«ã—ã¾ã™ã€‚

ã¾ãšã¯ candidate generation ã§ã™ã€‚ã“ã“ã§ã¯äº‹å‰ã«ä½œæˆã—ã¦ãŠã„ãŸ index ã‚’ä½¿ã£ã¦å–å¾—ã—ã¾ã™ã€‚
```python
df_test = tfds.as_dataframe(test)

for x in test.batch(20_000):
    _, tmp = cand_index(x, k=10)
df_test['cand'] = tmp.numpy().tolist()
```

ç¶šã„ã¦ re-ranking ã§ã™ã€‚å–å¾—ã—ãŸ candidate ãã‚Œãã‚Œã«å¯¾ã—ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã«å¤šå°‘é¢å€’ãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã„ã¾ã™ã€‚å˜ã« ranking model ã§ã‚¹ã‚³ã‚¢ã‚’å‡ºã—ã¦ãã®é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ã„ã‚‹ã ã‘ã§ã™ã€‚
```python
df_test['orig_index'] = df_test.index
df_test = df_test.query('user_pref==1')

# ãƒªã‚¹ãƒˆã®å„è¦ç´ ã‚’å„è¡Œã«
df_test_exp = df_test[['user_id', 'timestamp', 'cand', 'orig_index']].explode('cand')

# Inference
scores = ranking_model.ranking_model.predict({
    'user_id':df_test_exp.user_id,
    'timestamp': df_test_exp.timestamp,
    'movie_title': df_test_exp.cand
})
df_test_exp['ranking_score'] = scores[:, 0]

# ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
df_test = pd.merge(
    df_test,
    df_test_exp.groupby('orig_index').ranking_score.apply(np.array).reset_index(name='ranking_score'),
    on=['orig_index']
)
df_test['pred'] = df_test.apply(lambda x: np.array(x['cand'])[np.argsort(-x['ranking_score'])], axis=1)
```

ã§ã¯è©•ä¾¡ã‚’ã—ã¾ã™ã€‚nDCG ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå¼ã§è¨ˆç®—ã—ã¾ã™ã€‚10ä»¶ã®ä¸­ã§ã€groud_truth ã‚’ä¸Šã«æŒã£ã¦ã“ã‚Œã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
```python
def ndcg(pred, gt):
    try:
        idx = pred.index(gt) + 1
        return 1.0 / np.log2(idx + 1)
    except ValueError:
        return 0
```
ä»¥ä¸‹çµæœã§ã™ã€‚

```python
df_test.apply(lambda row: ndcg(row['cand'], row['movie_title']), axis=1).mean()
>>> 0.005736147190140732
df_test.apply(lambda row: ndcg(row['pred'].tolist(), row['movie_title']), axis=1).mean()
>>> 0.007693552905167569
```
ä¸‹ã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°å¾Œã®æ–¹ãŒã€nDCG ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚Retrieval ãƒ¢ãƒ‡ãƒ«ã¯ rating ãŒé«˜ã„ã‹ä½ã„ã‹ã¨ã„ã†æƒ…å ±ã‚’å­¦ã°ã›ã¦ã„ãªã„ã®ã§ã€å½“ç„¶ã¨è¨€ãˆã°å½“ç„¶ãªã®ã§ã™ãŒã€æœŸå¾…é€šã‚Šã®çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚


# ãã®ä»–
TFRSã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã¯ãã‚“ãªã«è¤‡é›‘ã§ã¯ãªã„ã®ã§ã€åˆ¥ã«ã‚ã–ã‚ã–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦åˆ‡ã‚Šå‡ºã™å¿…è¦ã‚‚ãªã•ãã†ãªæ°—ãŒã—ã¾ã™ã€‚Googleã¨ã—ã¦ã¯ã€DNNã‚’ä½¿ã£ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨ã—ã¦æ™®åŠã•ã›ã‚ˆã†ã¨ã„ã†æ„Ÿã˜ãªã®ã§ã—ã‚‡ã†ã‹ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ç›®ã‚’é€šã™ã“ã¨ã§ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã«ãŠã‘ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ´»ç”¨ã®å‹‰å¼·ã«ã¯ãªã‚‹ã¨æ€ã„ã¾ã™ã€‚
